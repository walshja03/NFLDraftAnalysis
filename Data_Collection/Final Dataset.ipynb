{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# from bs4 import BeautifulSoup\n",
    "# from splinter import Browser\n",
    "# import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to standardize names\n",
    "def stdName(df,col_to_split):\n",
    "    \n",
    "    #Separate out players first and last name for joining later\n",
    "    df[[\"FirstNm\",\"Last\"]] = df[col_to_split].str.split(\" \",n=1,expand=True)\n",
    "    df['FirstNm']=df['FirstNm'].str.upper()\n",
    "    df['Last']=df['Last'].str.upper()\n",
    "\n",
    "    #Get rid of , and . which may be inconsistent based on sample\n",
    "    df['Last']=df['Last'].str.replace('.','')\n",
    "    df['Last']=df['Last'].str.replace(',','')\n",
    "\n",
    "    df['FirstNm']=df['FirstNm'].str.replace('.','')\n",
    "    df['FirstNm']=df['FirstNm'].str.replace(',','')\n",
    "\n",
    "    #Add preceeding , to common suffixes for parsing out\n",
    "    df['Last']=df['Last'].str.replace(' JR',',JR')\n",
    "    df['Last']=df['Last'].str.replace(', JR',',JR')\n",
    "    df['Last']=df['Last'].str.replace(' II',',II')\n",
    "    df['Last']=df['Last'].str.replace(' III',',III')\n",
    "    df['Last']=df['Last'].str.replace(' SR',',SR')\n",
    "    df['Last']=df['Last'].str.replace(' V',',V')\n",
    "\n",
    "#     parse out the suffix from the last name\n",
    "    df[['LastNm','Suffix']]=df['Last'].str.split(\",\",n=1,expand=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get csv files\n",
    "def get_csv(filename):\n",
    "    path = os.path.abspath('')\n",
    "    filepath = f\"{path}/FPTS/{filename}.csv\"\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to replace null values with an average factored by a penalty\n",
    "def fill_null_floats(df,col_headers,penalty=0):\n",
    "    df = df.fillna(\"NoRecord\")\n",
    "    for col in col_headers:\n",
    "        mean_df = df[df[col]!='NoRecord']\n",
    "        average = mean_df[col].astype(float).mean()\n",
    "        print(average)\n",
    "        df[col]=df[col].replace(to_replace='NoRecord',value = (average-penalty))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in all files created of Year and fantasy points by player and concatenate together.\n",
    "files = ['2008Fpts','2009Fpts','2010Fpts','2011Fpts','2012Fpts','2013Fpts','2014Fpts','2015Fpts','2016Fpts','2017Fpts','2018Fpts','2019Fpts']\n",
    "fpt_df =[]\n",
    "for file in files:\n",
    "    path = (get_csv(file))\n",
    "    df = pd.read_csv(path)\n",
    "    fpt_df.append(df)\n",
    "#Put all the files into 1 dataframe\n",
    "Fantasy_df = pd.concat(fpt_df)\n",
    "\n",
    "#Strip some specific name editions that was attached to names\n",
    "Fantasy_df['Player']=Fantasy_df['Player'].map(lambda x: x.rstrip(' PUP'))\n",
    "Fantasy_df['Player']=Fantasy_df['Player'].map(lambda x: x.rstrip(' SUS'))\n",
    "Fantasy_df['Player']=Fantasy_df['Player'].map(lambda x: x.rstrip(' o'))\n",
    "Fantasy_df['Player']=Fantasy_df['Player'].map(lambda x: x.rstrip(' II'))\n",
    "#run overall name standardization\n",
    "Fantasy_df=stdName(Fantasy_df,'Player')\n",
    "\n",
    "# Save to a CSV file.  Commented out to prevent overwriting files\n",
    "# Fantasy_df.to_csv(\"fantasypts2.csv\")\n",
    "\n",
    "#Read in a standardize names of college stats\n",
    "college_df = pd.read_csv(\"allcollegestat.csv\")\n",
    "college_df=stdName(college_df,'Player')\n",
    "\n",
    "#drop career games column because it's blank\n",
    "college_df.drop(columns = ['careergames'], inplace = True)\n",
    "#fill missing college stats with 0\n",
    "college_df.fillna(0,inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df = pd.read_csv('combine.csv')\n",
    "combine_df=stdName(combine_df,'Player')\n",
    "\n",
    "collcomb = college_df.merge(combine_df, on = ['FirstNm','LastNm'], how = 'left')\n",
    "#drop extra Mike Williamss after merge\n",
    "collcomb.drop(index = [292,295], inplace = True)\n",
    "\n",
    "#Limit dataset to those that have\n",
    "include3 = ['2009','2010','2011','2012','2013','2014','2015','2016']\n",
    "# include4 = ['2009','2010','2011','2012','2013','2014','2015']\n",
    "draft2020 = collcomb[collcomb['year']==2020]\n",
    "sim_data3 = collcomb[collcomb['year'].isin(include3)]\n",
    "# sim_data4 = collcomb[collcomb['year'].isin(include4)]\n",
    "sim_data3.sort_values('year')\n",
    "\n",
    "fname = sim_data3['FirstNm'].values\n",
    "fname\n",
    "lname = sim_data3['LastNm'].values\n",
    "lname\n",
    "draftyear = sim_data3['year'].values\n",
    "name_yr_dict = {'firstnm':fname,'lastnm':lname,'draftyr':draftyear}\n",
    "name_yr_dict['draftyr'][0]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code will go through the dictionary of individuals that were drafted and return the fantasy points scored in their\n",
    "#first 3 seasons\n",
    "\n",
    "#list to collect individual dfs\n",
    "ind_df = []\n",
    "no_stats = []\n",
    "failures = []\n",
    "success= []\n",
    "for i in range(len(fname)):\n",
    "    #create a list of first 3 years in the league for each player\n",
    "    years =[round(name_yr_dict['draftyr'][i],0),round(name_yr_dict['draftyr'][i]+1,0),round(name_yr_dict['draftyr'][i]+2,0)]\n",
    "    \n",
    "    #get first and last name of each record\n",
    "    first = name_yr_dict['firstnm'][i]\n",
    "    last = name_yr_dict['lastnm'][i]\n",
    "    \n",
    "    #get a conditional dataframe of players\n",
    "    try:\n",
    "        indiv_df = Fantasy_df[(Fantasy_df['FirstNm']==first) & (Fantasy_df['LastNm']==last)]\n",
    "        \n",
    "        \n",
    "        \n",
    "        try:\n",
    "            fant_indiv = indiv_df[indiv_df['Year'].isin(years)]\n",
    "            df = fant_indiv.groupby('Player').sum()\n",
    "            df.reset_index(inplace =True)\n",
    "            df.drop(columns = ['Year'], inplace = True)\n",
    "            df['FirstNm']=first\n",
    "            df['LastNm']=last\n",
    "            \n",
    "            if len(df)>0:\n",
    "                ind_df.append(df)\n",
    "                print(f\"{first} {last}: success\")\n",
    "                success.append(f\"{first} {last}\")\n",
    "                if len(ind_df)==1:\n",
    "                    fant_summ_df = df\n",
    "                    print(\"appended\")\n",
    "                else:\n",
    "                    fant_summ_df = pd.concat([fant_summ_df,df])\n",
    "                    print(comb_df)\n",
    "            else:\n",
    "                print(f\"{first} {last}: no stats {years}\")\n",
    "                no_stats.append(f\"{first} {last}\")\n",
    "                new_row = {'Player':'no points','FPTS':0,'FirstNm':first,'LastNm':last}\n",
    "                fant_summ_df = fant_summ_df.append(new_row,ignore_index = True)\n",
    "                print(\"appended\")\n",
    "        except:\n",
    "            print(\"fail\")\n",
    "    except: \n",
    "        print(f\"{first} {last}: no stats\")\n",
    "        failures.append(f\"{first} {last}\")\n",
    "        \n",
    "#list of columns that need to be floats and adjusted to null values\n",
    "col_replace = ['40YD','Vertical', 'BenchReps', 'Broad Jump', '3Cone', 'Shuttle']\n",
    "\n",
    "#replace null values and convert measurables to floats using function defined above\n",
    "sim_data3 = fill_null_floats(sim_data3,col_replace)\n",
    "draft2020=fill_null_floats(draft2020,col_replace)\n",
    "\n",
    "final3 = sim_data3.merge(fant_summ_df, how = 'inner',on = ['FirstNm','LastNm'])\n",
    "\n",
    "model = final3.drop(columns=['Unnamed: 0_x','Year_x','Pos_x','Last_x','Suffix_x','Unnamed: 0_y', 'Rk', 'Year_y','Player_y', 'Pos_y',\n",
    "                    'School_y','Last_y', 'Suffix_y', 'Player','School_x','Team','Round'])\n",
    "\n",
    "#reset index to get a column with a unique number\n",
    "model.reset_index(inplace = True)\n",
    "#rename that column ID\n",
    "model.rename(columns = {'index':'ID'}, inplace = True)\n",
    "\n",
    "#create CSV file of data to read into model- NOTE: Commented out because of manual adjustments\n",
    "# model.to_csv(\"modelPython.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
